{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Model Building Leveraging Bayesian Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from pymc3 import  *\n",
    "import pymc3 as pm\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from bambi import Model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import warnings\n",
    "# Suppressing warnings.  It's bad... but they're so annoying \n",
    "# and almost always for developers and not me. \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal is develop an automated model building routine give certain constraints. To start, lets list the constraints:\n",
    "* Model is limited to linear regression or logistic regression with random effects\n",
    "* Data will be tabular\n",
    "* Numeric Inputs will be scale-free\n",
    "\n",
    "The algorithm.  When we take some time to think about what we are trying to implement, it becomes pretty clear that the task we're trying to solve is a simple tree search.  The problem is that as the number of available nodes is quite large and training a single model can take a while, so we would like to be intelligent about the nodes that we visit.  A popular method for approaching this method is Monte Carlo Tree Search. \n",
    "\n",
    "The challenge is that MCTS has really been developed and framed in terms of games.  Model building is certainly a type of game, and so far we don't have a reason to believe that the method doesn't fit.  However, one feature of MCTS is the ability to evaluate a position. \n",
    "\n",
    "In order to test our method, we will want some datasets to use as well.  To start I think we will use the American National Election Survey from 1996. This dataset, sampled below, has a nice mix of categorical and numeric variables and is a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popul</th>\n",
       "      <th>TVnews</th>\n",
       "      <th>selfLR</th>\n",
       "      <th>ClinLR</th>\n",
       "      <th>DoleLR</th>\n",
       "      <th>PID</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>income</th>\n",
       "      <th>vote</th>\n",
       "      <th>logpopul</th>\n",
       "      <th>nage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.672432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.247550</td>\n",
       "      <td>-1.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437208</td>\n",
       "      <td>-1.403108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.420045</td>\n",
       "      <td>-1.159549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.461624</td>\n",
       "      <td>1.276040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popul  TVnews  selfLR  ClinLR  DoleLR  PID   age  educ  income  vote  \\\n",
       "0    0.0     7.0     7.0     1.0     6.0  6.0  36.0   3.0     1.0   1.0   \n",
       "1  190.0     1.0     3.0     3.0     5.0  1.0  20.0   4.0     1.0   0.0   \n",
       "2   31.0     7.0     2.0     2.0     6.0  1.0  24.0   6.0     1.0   0.0   \n",
       "3   83.0     4.0     3.0     4.0     5.0  1.0  28.0   6.0     1.0   0.0   \n",
       "4  640.0     7.0     5.0     6.0     4.0  0.0  68.0   6.0     1.0   0.0   \n",
       "\n",
       "   logpopul      nage  \n",
       "0 -2.302585 -0.672432  \n",
       "1  5.247550 -1.646667  \n",
       "2  3.437208 -1.403108  \n",
       "3  4.420045 -1.159549  \n",
       "4  6.461624  1.276040  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sm.datasets.anes96.load_pandas().data\n",
    "data['nage'] = (data.age - data.age.mean()) / data.age.std()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'vote'\n",
    "numeric = np.array(['nage'])\n",
    "categorical = np.array(['educ', 'income'])\n",
    "\n",
    "def get_ranefs(numeric, categorical):\n",
    "    '''Generates a list of ranefs\n",
    "    Given just the list of numeric and categorical variables, we can generate\n",
    "    a list of all potential features we might explore.\n",
    "    '''\n",
    "    random_slopes = [f'0 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "    random_linear = [f'1 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "    return np.array(random_slopes + random_linear)\n",
    "\n",
    "ranefs =  get_ranefs(numeric, categorical)\n",
    "features = np.hstack([numeric, categorical, ranefs])\n",
    "\n",
    "model_array = np.array([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "i = len(numeric)\n",
    "j = len(categorical)\n",
    "intercept = model_array[0]\n",
    "selected_numeric = numeric[model_array[1:i+1] == 1]\n",
    "selected_categorical = categorical[model_array[i+1:i+j+1] == 1]\n",
    "selected_ranefs = ranefs[model_array[i+j+1:] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_array, features, target, data):\n",
    "    \"\"\" Builds an arbitrary Bambi model\n",
    "    \n",
    "    Args:\n",
    "      model_array: A vector of boolean values which map to the feature array\n",
    "      features: A triple of arrays with the string names of variables included in the search\n",
    "      target: The string name of the target variable\n",
    "      data: A pandas dataframe with the features and target\n",
    "    \"\"\"\n",
    "    # Pull apart the tuple for convenience\n",
    "    numeric, categorical, ranefs = features\n",
    "    numeric, categorical, ranefs = np.array(numeric), np.array(categorical), np.array(ranefs)\n",
    "    model_array = np.array(model_array)\n",
    "    \n",
    "    # Determine which features are in the model\n",
    "    i = len(numeric)\n",
    "    j = len(categorical)\n",
    "    selected_numeric = numeric[model_array[:i] == 1]\n",
    "    selected_categorical = categorical[model_array[i:i+j] == 1]\n",
    "    selected_ranefs = ranefs[model_array[i+j:] == 1]\n",
    "    \n",
    "    print(f\"Fitting with the following features: {selected_numeric}, {selected_categorical}, {selected_ranefs}\")\n",
    "    \n",
    "    model = Model(data)\n",
    "    for feature in selected_numeric:\n",
    "        model.add(feature)\n",
    "    for feature in selected_categorical:\n",
    "        model.add(feature, categorical=[feature])\n",
    "    for feature in selected_ranefs:\n",
    "        model.add(random=[feature])\n",
    "    model.add(target + '~ 1')\n",
    "    results = model.fit(family='bernoulli', progressbar=False)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model):\n",
    "    waic = pm.waic(model.backend.trace, model.backend.model)\n",
    "    return waic.WAIC, waic.WAIC_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have the ability to generate an array of binary elements which corresponds to the entire search space, and a function which given that array can fit and evaluate the model.  This is pretty close to what we preliminarily need for Monte Carlo Tree Search.  The only thing to add is the strategy we'll use for searching the tree.\n",
    "\n",
    "A few different thoughts come to mind:\n",
    "* Randomly sampling from the search space\n",
    "  * In this model we would enumerate nodes as we evaluated them, but have no preference for which node we choose.  The best model would be chosen after a fixed amount of time or number of models evaluated.\n",
    "* Weighted random sampling\n",
    "  * In this version we would use the WAIC score\n",
    "\n",
    "To develop the class for MCTS, we will step through what the process might look like manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will be initialized with a number of now expected elements\n",
    "target = 'vote'\n",
    "numeric = np.array(['nage'])\n",
    "categorical = np.array(['educ', 'income'])\n",
    "# It will probably just internally generate the ranefs for convenience\n",
    "ranefs =  get_ranefs(numeric, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vars = len(np.hstack([numeric, categorical, ranefs]))\n",
    "# Initialize model array\n",
    "model_array = np.zeros(n_vars, np.int32)\n",
    "model_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 1, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 1, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 1, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine set of next possible models given a model array\n",
    "model_array = np.array([1, 0, 0, 0, 0, 0, 0])\n",
    "next_moves = []\n",
    "for ix, val in enumerate(model_array):\n",
    "    if val != 1:\n",
    "        move = model_array.copy()\n",
    "        move[ix] = 1\n",
    "        next_moves.append(move)\n",
    "        \n",
    "next_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_node(model_array, models, parent_score=0):\n",
    "    \"\"\"Enumerates all possible models which build off of the given model\"\"\"\n",
    "    model_array = np.array(model_array)\n",
    "    for ix, val in enumerate(model_array):\n",
    "        if val != 1:\n",
    "            move = model_array.copy()\n",
    "            move[ix] = 1\n",
    "            models = models.append({\"models\":str(move.astype('int')), \"parent_score\":parent_score}, ignore_index=True)\n",
    "    return models\n",
    "\n",
    "def best_model(models):\n",
    "    \"\"\"Given a dataframe of scores, returns the best\"\"\"\n",
    "    best = models[models.scores == models.scores.min()]\n",
    "    return best.models.iloc[0]\n",
    "\n",
    "def random_sampling_strategy(samples):\n",
    "    \"\"\"The Random Sampling E.g. No Particular Strategy\n",
    "    \n",
    "    In this strategy we start by enumerating the root and giving every model\n",
    "    equal probability of being chosen.  Then as each model is sampled, we \n",
    "    enumerate the possible model from that node. \n",
    "    \"\"\"\n",
    "    # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            sample_string = models[np.isnan(models.scores)].sample(1)['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 18700\n",
      "Interrupted at 18,699 [37%]: Average Loss = 2,047.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 19000\n",
      "Interrupted at 18,999 [37%]: Average Loss = 2,490.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, nage, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "models = random_sampling_strategy(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0 0 1 0 0 0 0]</td>\n",
       "      <td>1343.175577</td>\n",
       "      <td>16.35646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>1340.540687</td>\n",
       "      <td>16.86136</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models       scores     error  parent_score\n",
       "0   [1 0 0 0 0 0 0]          NaN       NaN      0.000000\n",
       "1   [0 1 0 0 0 0 0]          NaN       NaN      0.000000\n",
       "2   [0 0 1 0 0 0 0]  1343.175577  16.35646      0.000000\n",
       "3   [0 0 0 1 0 0 0]          NaN       NaN      0.000000\n",
       "4   [0 0 0 0 1 0 0]          NaN       NaN      0.000000\n",
       "5   [0 0 0 0 0 1 0]          NaN       NaN      0.000000\n",
       "6   [0 0 0 0 0 0 1]          NaN       NaN      0.000000\n",
       "7   [1 0 1 0 0 0 0]  1340.540687  16.86136   1375.888497\n",
       "8   [0 1 1 0 0 0 0]          NaN       NaN   1375.888497\n",
       "9   [0 0 1 1 0 0 0]          NaN       NaN   1375.888497\n",
       "10  [0 0 1 0 1 0 0]          NaN       NaN   1375.888497\n",
       "11  [0 0 1 0 0 1 0]          NaN       NaN   1375.888497\n",
       "12  [0 0 1 0 0 0 1]          NaN       NaN   1375.888497\n",
       "13  [1 1 1 0 0 0 0]          NaN       NaN   1374.263408\n",
       "14  [1 0 1 1 0 0 0]          NaN       NaN   1374.263408\n",
       "15  [1 0 1 0 1 0 0]          NaN       NaN   1374.263408\n",
       "16  [1 0 1 0 0 1 0]          NaN       NaN   1374.263408\n",
       "17  [1 0 1 0 0 0 1]          NaN       NaN   1374.263408"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "      <td>-0.948683</td>\n",
       "      <td>0.012429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "      <td>-0.948683</td>\n",
       "      <td>0.012429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "      <td>-0.948683</td>\n",
       "      <td>0.012429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "      <td>-0.948683</td>\n",
       "      <td>0.012429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.888497</td>\n",
       "      <td>-0.948683</td>\n",
       "      <td>0.012429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.082879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.082879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.082879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.082879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374.263408</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.082879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models  scores  error  parent_score    Normed         p\n",
       "0   [1 0 0 0 0 0 0]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "1   [0 1 0 0 0 0 0]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "3   [0 0 0 1 0 0 0]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "4   [0 0 0 0 1 0 0]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "5   [0 0 0 0 0 1 0]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "6   [0 0 0 0 0 0 1]     NaN    NaN      0.000000  1.000000  0.087243\n",
       "8   [0 1 1 0 0 0 0]     NaN    NaN   1375.888497 -0.948683  0.012429\n",
       "9   [0 0 1 1 0 0 0]     NaN    NaN   1375.888497 -0.948683  0.012429\n",
       "10  [0 0 1 0 1 0 0]     NaN    NaN   1375.888497 -0.948683  0.012429\n",
       "11  [0 0 1 0 0 1 0]     NaN    NaN   1375.888497 -0.948683  0.012429\n",
       "12  [0 0 1 0 0 0 1]     NaN    NaN   1375.888497 -0.948683  0.012429\n",
       "13  [1 1 1 0 0 0 0]     NaN    NaN   1374.263408  0.948683  0.082879\n",
       "14  [1 0 1 1 0 0 0]     NaN    NaN   1374.263408  0.948683  0.082879\n",
       "15  [1 0 1 0 1 0 0]     NaN    NaN   1374.263408  0.948683  0.082879\n",
       "16  [1 0 1 0 0 1 0]     NaN    NaN   1374.263408  0.948683  0.082879\n",
       "17  [1 0 1 0 0 0 1]     NaN    NaN   1374.263408  0.948683  0.082879"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to calculate weights\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def calculate_weights(all_models, root_offset=0):\n",
    "    \"\"\"Calculates valid probabilites which sum to one\n",
    "    \n",
    "    In our strategy, we want to take into account both the expected\n",
    "    WAIC and the error in the term.  As a result, we'll calculate \n",
    "    actually calculate the upper 95% value, or the mean plus two\n",
    "    standard deviations.  This will help penalize high variance\n",
    "    models. \n",
    "    \"\"\"\n",
    "    # Extracts non-zero parent scores\n",
    "    models = all_models[np.isnan(all_models.scores)]\n",
    "    # Calculates mean and std deviation unbiased by zero values\n",
    "    mean = models[models.parent_score != 0]['parent_score'].mean()\n",
    "    if all_models[~np.isnan(all_models.scores)].shape[0] == 1:\n",
    "        std = 1\n",
    "    else:\n",
    "        std = models[models.parent_score != 0]['parent_score'].std()\n",
    "        \n",
    "    # Calcultes the z scores for each non zero parent score\n",
    "    # Increase the root offset to make it more likely for the model to try different\n",
    "    # univariate models. \n",
    "    models['Normed'] = [root_offset if score == 0 else (-(score-mean)/std)  for score in models.parent_score]\n",
    "    models['p'] = softmax(models.Normed)\n",
    "    return models\n",
    "\n",
    "weights = calculate_weights(models, root_offset=1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sampling_strategy(samples):\n",
    "    \"\"\"The Weighted Sampling Strategy\n",
    "    \n",
    "    In this case we would like to sample from the tree more strategically,\n",
    "    using some kind of heuristic to guide our sampling as we gain information\n",
    "    from each evaluated model. \n",
    "    \n",
    "    The primary difference will be that instead of sampling from the possible \n",
    "    nodes equally, we'll weight them based on the evaluated WAIC.  To do this we'll\n",
    "    need to create a calculate_weights function which takes some scores and \n",
    "    evaluates valid weights which we can pass to an RNG. \n",
    "    \"\"\"\n",
    "   # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            # Calculate Weights\n",
    "            weights = calculate_weights(models, root_offset=1)\n",
    "            # Draw Sample\n",
    "            sample_record = models[np.isnan(models.scores)].sample(1, weights=weights['p'])\n",
    "            sample_string = sample_record['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            #print(model_array)\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,425\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], [], ['1 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,523.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd, 1| educ_offset, 1| educ_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ' '1 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 18900\n",
      "Interrupted at 18,899 [37%]: Average Loss = 1,539.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, 1| educ_offset, 1| educ_sd, nage| educ_offset, nage| educ_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "models = weighted_sampling_strategy(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>1343.087952</td>\n",
       "      <td>12.030390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 0 0 1 0 1 0]</td>\n",
       "      <td>1343.116178</td>\n",
       "      <td>12.064732</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 0 1 0 1 0]</td>\n",
       "      <td>1343.116178</td>\n",
       "      <td>12.064732</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>1343.747162</td>\n",
       "      <td>11.553305</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 0 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 0 0 1 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 0 0 0 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 0 0 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 0 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 0 1 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 0 0 1 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 0 0 1 0 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models       scores      error  parent_score\n",
       "5   [0 0 0 0 0 1 0]  1343.087952  12.030390      0.000000\n",
       "11  [0 0 0 1 0 1 0]  1343.116178  12.064732   1366.853772\n",
       "16  [0 0 0 1 0 1 0]  1343.116178  12.064732   1367.148732\n",
       "3   [0 0 0 1 0 0 0]  1343.747162  11.553305      0.000000\n",
       "0   [1 0 0 0 0 0 0]          NaN        NaN      0.000000\n",
       "1   [0 1 0 0 0 0 0]          NaN        NaN      0.000000\n",
       "2   [0 0 1 0 0 0 0]          NaN        NaN      0.000000\n",
       "4   [0 0 0 0 1 0 0]          NaN        NaN      0.000000\n",
       "6   [0 0 0 0 0 0 1]          NaN        NaN      0.000000\n",
       "7   [1 0 0 1 0 0 0]          NaN        NaN   1366.853772\n",
       "8   [0 1 0 1 0 0 0]          NaN        NaN   1366.853772\n",
       "9   [0 0 1 1 0 0 0]          NaN        NaN   1366.853772\n",
       "10  [0 0 0 1 1 0 0]          NaN        NaN   1366.853772\n",
       "12  [0 0 0 1 0 0 1]          NaN        NaN   1366.853772\n",
       "13  [1 0 0 0 0 1 0]          NaN        NaN   1367.148732\n",
       "14  [0 1 0 0 0 1 0]          NaN        NaN   1367.148732\n",
       "15  [0 0 1 0 0 1 0]          NaN        NaN   1367.148732\n",
       "17  [0 0 0 0 1 1 0]          NaN        NaN   1367.148732\n",
       "18  [0 0 0 0 0 1 1]          NaN        NaN   1367.148732\n",
       "19  [1 0 0 1 0 1 0]          NaN        NaN   1367.245642\n",
       "20  [0 1 0 1 0 1 0]          NaN        NaN   1367.245642\n",
       "21  [0 0 1 1 0 1 0]          NaN        NaN   1367.245642\n",
       "22  [0 0 0 1 1 1 0]          NaN        NaN   1367.245642\n",
       "23  [0 0 0 1 0 1 1]          NaN        NaN   1367.245642"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(\"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point we've only been testing with *3 variables*.  I think it's time to turn it up a notch, and see it handles more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will be initialized with a number of now expected elements\n",
    "target = 'vote'\n",
    "\n",
    "\n",
    "numeric = np.array(['nage', 'logpopul'])\n",
    "categorical = np.array(['educ', 'income', 'PID', 'selfLR'])\n",
    "# It will probably just internally generate the ranefs for convenience\n",
    "ranefs =  get_ranefs(numeric, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + logpopul | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19300\n",
      "Interrupted at 19,299 [38%]: Average Loss = 1,582.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| income_offset, logpopul| income_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 21400\n",
      "Interrupted at 21,399 [42%]: Average Loss = 1,279.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, PID, Intercept]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 13400\n",
      "Interrupted at 13,399 [26%]: Average Loss = 1,868.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| selfLR_offset, logpopul| selfLR_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,437.4\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| income_offset, nage| income_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,011.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19800\n",
      "Interrupted at 19,799 [39%]: Average Loss = 1,434\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22600\n",
      "Interrupted at 22,599 [45%]: Average Loss = 1,248.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, Intercept]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['PID'], ['1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23000\n",
      "Interrupted at 22,999 [45%]: Average Loss = 1,334.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, PID, Intercept]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 25100\n",
      "Interrupted at 25,099 [50%]: Average Loss = 1,784\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, PID, educ, Intercept]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24200\n",
      "Interrupted at 24,199 [48%]: Average Loss = 2,026.6\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24900\n",
      "Interrupted at 24,899 [49%]: Average Loss = 2,097.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,304.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, PID, Intercept]\n",
      "There were 35 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.635539885527753, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 907 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.31780144076287675, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + nage | income' '1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,359.9\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, Intercept]\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 62 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['income' 'PID'], ['1 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 24700\n",
      "Interrupted at 24,699 [49%]: Average Loss = 1,747.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, income, Intercept]\n",
      "There were 80 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6793447308206073, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 182 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6507623216419204, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | income' '1 + logpopul | PID' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 26200\n",
      "Interrupted at 26,199 [52%]: Average Loss = 2,044.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "There were 56 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7157034995752866, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 105 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19000\n",
      "Interrupted at 18,999 [37%]: Average Loss = 1,918.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | PID' '1 + logpopul | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23900\n",
      "Interrupted at 23,899 [47%]: Average Loss = 2,303.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, PID, educ, Intercept]\n",
      "There were 25 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 67 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['0 + nage | PID' '1 + nage | income' '1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22700\n",
      "Interrupted at 22,699 [45%]: Average Loss = 1,440.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, nage| PID_offset, nage| PID_sd, PID, Intercept]\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 24 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | educ' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 26300\n",
      "Interrupted at 26,299 [52%]: Average Loss = 1,913.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| educ_offset, nage| educ_sd, 1| educ_offset, 1| educ_sd, PID, educ, Intercept]\n",
      "There were 123 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 206 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], ['PID'], ['0 + nage | selfLR' '1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 21800\n",
      "Interrupted at 21,799 [43%]: Average Loss = 1,371\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, nage| selfLR_offset, nage| selfLR_sd, PID, Intercept]\n",
      "There were 886 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.02504323089484991, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 911 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.3737059451330113, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    }
   ],
   "source": [
    "models = weighted_sampling_strategy(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>1347.364258</td>\n",
       "      <td>12.588133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0 0 1 0 0 0 0]</td>\n",
       "      <td>1344.256783</td>\n",
       "      <td>16.392886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 1 0 0 1 0 0]</td>\n",
       "      <td>1347.380481</td>\n",
       "      <td>12.785435</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models       scores      error  parent_score    Normed\n",
       "0   [1 0 0 0 0 0 0]          NaN        NaN      0.000000  0.000000\n",
       "1   [0 1 0 0 0 0 0]  1347.364258  12.588133      0.000000  0.000000\n",
       "2   [0 0 1 0 0 0 0]  1344.256783  16.392886      0.000000  0.000000\n",
       "3   [0 0 0 1 0 0 0]          NaN        NaN      0.000000  0.000000\n",
       "4   [0 0 0 0 1 0 0]          NaN        NaN      0.000000  0.000000\n",
       "5   [0 0 0 0 0 1 0]          NaN        NaN      0.000000  0.000000\n",
       "6   [0 0 0 0 0 0 1]          NaN        NaN      0.000000  0.000000\n",
       "7   [1 1 0 0 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "8   [0 1 1 0 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "9   [0 1 0 1 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "10  [0 1 0 0 1 0 0]  1347.380481  12.785435   1372.540524  0.801798\n",
       "11  [0 1 0 0 0 1 0]          NaN        NaN   1372.540524  0.801798\n",
       "12  [0 1 0 0 0 0 1]          NaN        NaN   1372.540524  0.801798\n",
       "13  [1 0 1 0 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "14  [0 1 1 0 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "15  [0 0 1 1 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "16  [0 0 1 0 1 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "17  [0 0 1 0 0 1 0]          NaN        NaN   1377.042555 -1.309417\n",
       "18  [0 0 1 0 0 0 1]          NaN        NaN   1377.042555 -1.309417\n",
       "19  [1 1 0 0 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "20  [0 1 1 0 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "21  [0 1 0 1 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "22  [0 1 0 0 1 1 0]          NaN        NaN   1372.951351  0.609143\n",
       "23  [0 1 0 0 1 0 1]          NaN        NaN   1372.951351  0.609143"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = calculate_weights(models.sort_values('scores'))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0]]),\n",
       " array([-0.57283494,  1.1546888 , -0.58185386]))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = models[~np.isnan(models.scores)]\n",
    "test_data = models[np.isnan(models.scores)]\n",
    "\n",
    "X_train = np.vstack(train_data.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "X_test = np.vstack(test_data.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "\n",
    "mean = train_data['scores'].mean()\n",
    "std = train_data['scores'].std()\n",
    "\n",
    "train_data['Normed'] = [0 if score == 0 else (-(score-mean)/std) for score in train_data.scores]\n",
    "y_train = train_data.Normed.values\n",
    "\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.522399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>0.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models  scores  error  parent_score    Normed  predictions\n",
       "0   [1 0 0 0 0 0 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "3   [0 0 0 1 0 0 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "4   [0 0 0 0 1 0 0]     NaN    NaN      0.000000  0.000000     0.050436\n",
       "5   [0 0 0 0 0 1 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "6   [0 0 0 0 0 0 1]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "7   [1 1 0 0 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "8   [0 1 1 0 0 0 0]     NaN    NaN   1372.540524  0.801798     0.210763\n",
       "9   [0 1 0 1 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "11  [0 1 0 0 0 1 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "12  [0 1 0 0 0 0 1]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "13  [1 0 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "14  [0 1 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.210763\n",
       "15  [0 0 1 1 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "16  [0 0 1 0 1 0 0]     NaN    NaN   1377.042555 -1.309417     0.522399\n",
       "17  [0 0 1 0 0 1 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "18  [0 0 1 0 0 0 1]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "19  [1 1 0 0 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "20  [0 1 1 0 1 0 0]     NaN    NaN   1372.951351  0.609143     0.050436\n",
       "21  [0 1 0 1 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "22  [0 1 0 0 1 1 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "23  [0 1 0 0 1 0 1]     NaN    NaN   1372.951351  0.609143    -0.421527"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "test_data['predictions'] = clf.predict(X_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.045670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>0.281908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models  scores  error  parent_score    Normed  predictions\n",
       "0   [1 0 0 0 0 0 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "3   [0 0 0 1 0 0 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "4   [0 0 0 0 1 0 0]     NaN    NaN      0.000000  0.000000     0.281908\n",
       "5   [0 0 0 0 0 1 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "6   [0 0 0 0 0 0 1]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "7   [1 1 0 0 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "8   [0 1 1 0 0 0 0]     NaN    NaN   1372.540524  0.801798     0.290927\n",
       "9   [0 1 0 1 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "11  [0 1 0 0 0 1 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "12  [0 1 0 0 0 0 1]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "13  [1 0 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "14  [0 1 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.290927\n",
       "15  [0 0 1 1 0 0 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "16  [0 0 1 0 1 0 0]     NaN    NaN   1377.042555 -1.309417     1.045670\n",
       "17  [0 0 1 0 0 1 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "18  [0 0 1 0 0 0 1]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "19  [1 1 0 0 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "20  [0 1 1 0 1 0 0]     NaN    NaN   1372.951351  0.609143     0.281908\n",
       "21  [0 1 0 1 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "22  [0 1 0 0 1 1 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "23  [0 1 0 0 1 0 1]     NaN    NaN   1372.951351  0.609143    -0.481854"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVR(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "test_data['predictions'] = svm.predict(X_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_sampling_strategy(samples):\n",
    "    \"\"\"The Predictive Sampling Strategy\n",
    "    \n",
    "    In this model we enhance our weight mechanism with predictions from\n",
    "    a support vector machine for our weights instead the heuristic that's\n",
    "    based on their parent score. \n",
    "    \n",
    "    This will hopefully help us identify related nodes in the tree and \n",
    "    prioritize them automatically. \n",
    "    \"\"\"\n",
    "   # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            # Calculate Weights\n",
    "            weights = calculate_weights(models, root_offset=1)\n",
    "            # Draw Sample\n",
    "            sample_record = models[np.isnan(models.scores)].sample(1, weights=weights['p'])\n",
    "            sample_string = sample_record['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            #print(model_array)\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mcts(object):\n",
    "    \n",
    "    def __init__(self, numeric, categorical, target):\n",
    "        self.target = target\n",
    "        self.numeric = np.array(numeric)\n",
    "        self.categorical = np.array(categorical)\n",
    "        self.ranefs = self.get_ranefs(numeric, categorical)\n",
    "        self.n_numeric = len(numeric)\n",
    "        self.n_categorical = len(categorical)\n",
    "        self.n_vars = len(numeric) + len(categorical) + len(self.ranefs)\n",
    "        self.root_node = np.zeros(self.n_vars, np.int32)\n",
    "        \n",
    "    \n",
    "    def enumerate_node(self, model_array, models, parent_score=0):\n",
    "        \"\"\"Enumerates all possible models which build off of the given model\"\"\"\n",
    "        model_array = np.array(model_array)\n",
    "        for ix, val in enumerate(model_array):\n",
    "            if val != 1:\n",
    "                move = model_array.copy()\n",
    "                move[ix] = 1\n",
    "                models = models.append({\"models\":str(move.astype('int')), \"parent_score\":parent_score}, ignore_index=True)\n",
    "        return models\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_ranefs(numeric, categorical):\n",
    "        '''Generates a list of ranefs\n",
    "        Given just the list of numeric and categorical variables, we can generate\n",
    "        a list of all potential features we might explore.\n",
    "        '''\n",
    "        random_slopes = [f'0 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "        random_linear = [f'1 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "        return np.array(random_slopes + random_linear)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = mcts(numeric, categorical, target)\n",
    "search.model_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
