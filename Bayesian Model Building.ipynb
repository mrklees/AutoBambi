{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Model Building Leveraging Bayesian Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\bayes\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from pymc3 import  *\n",
    "import pymc3 as pm\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from bambi import Model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import warnings\n",
    "# Suppressing warnings.  It's bad... but they're so annoying \n",
    "# and almost always for developers and not me. \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal is develop an automated model building routine give certain constraints. To start, lets list the constraints:\n",
    "* Model is limited to linear regression or logistic regression with random effects\n",
    "* Data will be tabular\n",
    "* Numeric Inputs will be scale-free\n",
    "\n",
    "The algorithm.  When we take some time to think about what we are trying to implement, it becomes pretty clear that the task we're trying to solve is a simple tree search.  The problem is that as the number of available nodes is quite large and training a single model can take a while, so we would like to be intelligent about the nodes that we visit.  A popular method for approaching this method is Monte Carlo Tree Search. \n",
    "\n",
    "The challenge is that MCTS has really been developed and framed in terms of games.  Model building is certainly a type of game, and so far we don't have a reason to believe that the method doesn't fit.  However, one feature of MCTS is the ability to evaluate a position. \n",
    "\n",
    "In order to test our method, we will want some datasets to use as well.  To start I think we will use the American National Election Survey from 1996. This dataset, sampled below, has a nice mix of categorical and numeric variables and is a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popul</th>\n",
       "      <th>TVnews</th>\n",
       "      <th>selfLR</th>\n",
       "      <th>ClinLR</th>\n",
       "      <th>DoleLR</th>\n",
       "      <th>PID</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>income</th>\n",
       "      <th>vote</th>\n",
       "      <th>logpopul</th>\n",
       "      <th>nage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-0.672432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.247550</td>\n",
       "      <td>-1.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437208</td>\n",
       "      <td>-1.403108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.420045</td>\n",
       "      <td>-1.159549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>640.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.461624</td>\n",
       "      <td>1.276040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popul  TVnews  selfLR  ClinLR  DoleLR  PID   age  educ  income  vote  \\\n",
       "0    0.0     7.0     7.0     1.0     6.0  6.0  36.0   3.0     1.0   1.0   \n",
       "1  190.0     1.0     3.0     3.0     5.0  1.0  20.0   4.0     1.0   0.0   \n",
       "2   31.0     7.0     2.0     2.0     6.0  1.0  24.0   6.0     1.0   0.0   \n",
       "3   83.0     4.0     3.0     4.0     5.0  1.0  28.0   6.0     1.0   0.0   \n",
       "4  640.0     7.0     5.0     6.0     4.0  0.0  68.0   6.0     1.0   0.0   \n",
       "\n",
       "   logpopul      nage  \n",
       "0 -2.302585 -0.672432  \n",
       "1  5.247550 -1.646667  \n",
       "2  3.437208 -1.403108  \n",
       "3  4.420045 -1.159549  \n",
       "4  6.461624  1.276040  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sm.datasets.anes96.load_pandas().data\n",
    "data['nage'] = (data.age - data.age.mean()) / data.age.std()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'vote'\n",
    "numeric = np.array(['nage'])\n",
    "categorical = np.array(['educ', 'income'])\n",
    "\n",
    "def get_ranefs(numeric, categorical):\n",
    "    '''Generates a list of ranefs\n",
    "    Given just the list of numeric and categorical variables, we can generate\n",
    "    a list of all potential features we might explore.\n",
    "    '''\n",
    "    random_slopes = [f'0 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "    random_linear = [f'1 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "    return np.array(random_slopes + random_linear)\n",
    "\n",
    "ranefs =  get_ranefs(numeric, categorical)\n",
    "features = np.hstack([numeric, categorical, ranefs])\n",
    "\n",
    "model_array = np.array([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "i = len(numeric)\n",
    "j = len(categorical)\n",
    "intercept = model_array[0]\n",
    "selected_numeric = numeric[model_array[1:i+1] == 1]\n",
    "selected_categorical = categorical[model_array[i+1:i+j+1] == 1]\n",
    "selected_ranefs = ranefs[model_array[i+j+1:] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_array, features, target, data):\n",
    "    \"\"\" Builds an arbitrary Bambi model\n",
    "    \n",
    "    Args:\n",
    "      model_array: A vector of boolean values which map to the feature array\n",
    "      features: A triple of arrays with the string names of variables included in the search\n",
    "      target: The string name of the target variable\n",
    "      data: A pandas dataframe with the features and target\n",
    "    \"\"\"\n",
    "    # Pull apart the tuple for convenience\n",
    "    numeric, categorical, ranefs = features\n",
    "    numeric, categorical, ranefs = np.array(numeric), np.array(categorical), np.array(ranefs)\n",
    "    model_array = np.array(model_array)\n",
    "    \n",
    "    # Determine which features are in the model\n",
    "    i = len(numeric)\n",
    "    j = len(categorical)\n",
    "    selected_numeric = numeric[model_array[:i] == 1]\n",
    "    selected_categorical = categorical[model_array[i:i+j] == 1]\n",
    "    selected_ranefs = ranefs[model_array[i+j:] == 1]\n",
    "    \n",
    "    print(f\"Fitting with the following features: {selected_numeric}, {selected_categorical}, {selected_ranefs}\")\n",
    "    \n",
    "    model = Model(data)\n",
    "    for feature in selected_numeric:\n",
    "        model.add(feature)\n",
    "    for feature in selected_categorical:\n",
    "        model.add(feature, categorical=[feature])\n",
    "    for feature in selected_ranefs:\n",
    "        model.add(random=[feature])\n",
    "    model.add(target + '~ 1')\n",
    "    results = model.fit(family='bernoulli', progressbar=False)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model):\n",
    "    waic = pm.waic(model.backend.trace, model.backend.model)\n",
    "    return waic.WAIC, waic.WAIC_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have the ability to generate an array of binary elements which corresponds to the entire search space, and a function which given that array can fit and evaluate the model.  This is pretty close to what we preliminarily need for Monte Carlo Tree Search.  The only thing to add is the strategy we'll use for searching the tree.\n",
    "\n",
    "A few different thoughts come to mind:\n",
    "* Randomly sampling from the search space\n",
    "  * In this model we would enumerate nodes as we evaluated them, but have no preference for which node we choose.  The best model would be chosen after a fixed amount of time or number of models evaluated.\n",
    "* Weighted random sampling\n",
    "  * In this version we would use the WAIC score\n",
    "\n",
    "To develop the class for MCTS, we will step through what the process might look like manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will be initialized with a number of now expected elements\n",
    "target = 'vote'\n",
    "numeric = np.array(['nage'])\n",
    "categorical = np.array(['educ', 'income'])\n",
    "# It will probably just internally generate the ranefs for convenience\n",
    "ranefs =  get_ranefs(numeric, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vars = len(np.hstack([numeric, categorical, ranefs]))\n",
    "# Initialize model array\n",
    "model_array = np.zeros(n_vars, np.int32)\n",
    "model_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 0, 0, 0, 0]),\n",
       " array([1, 0, 0, 1, 0, 0, 0]),\n",
       " array([1, 0, 0, 0, 1, 0, 0]),\n",
       " array([1, 0, 0, 0, 0, 1, 0]),\n",
       " array([1, 0, 0, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine set of next possible models given a model array\n",
    "model_array = np.array([1, 0, 0, 0, 0, 0, 0])\n",
    "next_moves = []\n",
    "for ix, val in enumerate(model_array):\n",
    "    if val != 1:\n",
    "        move = model_array.copy()\n",
    "        move[ix] = 1\n",
    "        next_moves.append(move)\n",
    "        \n",
    "next_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_node(model_array, models, parent_score=0):\n",
    "    \"\"\"Enumerates all possible models which build off of the given model\"\"\"\n",
    "    model_array = np.array(model_array)\n",
    "    for ix, val in enumerate(model_array):\n",
    "        if val != 1:\n",
    "            move = model_array.copy()\n",
    "            move[ix] = 1\n",
    "            models = models.append({\"models\":str(move.astype('int')), \"parent_score\":parent_score}, ignore_index=True)\n",
    "    models = models.drop_duplicates(subset=\"models\")\n",
    "    return models\n",
    "\n",
    "def best_model(models):\n",
    "    \"\"\"Given a dataframe of scores, returns the best\"\"\"\n",
    "    best = models[models.scores == models.scores.min()]\n",
    "    return best.models.iloc[0]\n",
    "\n",
    "def random_sampling_strategy(samples):\n",
    "    \"\"\"The Random Sampling E.g. No Particular Strategy\n",
    "    \n",
    "    In this strategy we start by enumerating the root and giving every model\n",
    "    equal probability of being chosen.  Then as each model is sampled, we \n",
    "    enumerate the possible model from that node. \n",
    "    \"\"\"\n",
    "    # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            sample_string = models[np.isnan(models.scores)].sample(1)['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 18700\n",
      "Interrupted at 18,699 [37%]: Average Loss = 2,047.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 19000\n",
      "Interrupted at 18,999 [37%]: Average Loss = 2,490.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, nage, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "models = random_sampling_strategy(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], [], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 12700\n",
      "Interrupted at 12,699 [25%]: Average Loss = 2,496.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage, Intercept]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bambi.models.Model at 0x28ae6fe1c88>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divergent = model.backend.trace['diverging']\n",
    "\n",
    "divperc = divergent.nonzero()[0].size / len(model.backend.trace) * 100\n",
    "\n",
    "divperc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to calculate weights\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def calculate_weights(all_models, root_offset=0):\n",
    "    \"\"\"Calculates valid probabilites which sum to one\n",
    "    \n",
    "    In our strategy, we want to take into account both the expected\n",
    "    WAIC and the error in the term.  As a result, we'll calculate \n",
    "    actually calculate the upper 95% value, or the mean plus two\n",
    "    standard deviations.  This will help penalize high variance\n",
    "    models. \n",
    "    \"\"\"\n",
    "    # Extracts non-zero parent scores\n",
    "    models = all_models[np.isnan(all_models.scores)]\n",
    "    # Calculates mean and std deviation unbiased by zero values\n",
    "    mean = models[models.parent_score != 0]['parent_score'].mean()\n",
    "    if all_models[~np.isnan(all_models.scores)].shape[0] == 1:\n",
    "        std = 1\n",
    "    else:\n",
    "        std = models[models.parent_score != 0]['parent_score'].std()\n",
    "        \n",
    "    # Calcultes the z scores for each non zero parent score\n",
    "    # Increase the root offset to make it more likely for the model to try different\n",
    "    # univariate models. \n",
    "    models['Normed'] = [root_offset if score == 0 else (-(score-mean)/std)  for score in models.parent_score]\n",
    "    models['p'] = softmax(models.Normed)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sampling_strategy(samples):\n",
    "    \"\"\"The Weighted Sampling Strategy\n",
    "    \n",
    "    In this case we would like to sample from the tree more strategically,\n",
    "    using some kind of heuristic to guide our sampling as we gain information\n",
    "    from each evaluated model. \n",
    "    \n",
    "    The primary difference will be that instead of sampling from the possible \n",
    "    nodes equally, we'll weight them based on the evaluated WAIC.  To do this we'll\n",
    "    need to create a calculate_weights function which takes some scores and \n",
    "    evaluates valid weights which we can pass to an RNG. \n",
    "    \"\"\"\n",
    "   # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            # Calculate Weights\n",
    "            weights = calculate_weights(models, root_offset=1)\n",
    "            # Draw Sample\n",
    "            sample_record = models[np.isnan(models.scores)].sample(1, weights=weights['p'])\n",
    "            sample_string = sample_record['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            #print(model_array)\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,425\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], [], ['1 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,523.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd, 1| educ_offset, 1| educ_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ' '1 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 18900\n",
      "Interrupted at 18,899 [37%]: Average Loss = 1,539.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, 1| educ_offset, 1| educ_sd, nage| educ_offset, nage| educ_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "models = weighted_sampling_strategy(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>1343.087952</td>\n",
       "      <td>12.030390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 0 0 1 0 1 0]</td>\n",
       "      <td>1343.116178</td>\n",
       "      <td>12.064732</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 0 1 0 1 0]</td>\n",
       "      <td>1343.116178</td>\n",
       "      <td>12.064732</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>1343.747162</td>\n",
       "      <td>11.553305</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 0 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 0 0 1 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.853772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 0 0 0 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.148732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 0 0 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 0 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 0 1 1 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 0 0 1 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 0 0 1 0 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.245642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models       scores      error  parent_score\n",
       "5   [0 0 0 0 0 1 0]  1343.087952  12.030390      0.000000\n",
       "11  [0 0 0 1 0 1 0]  1343.116178  12.064732   1366.853772\n",
       "16  [0 0 0 1 0 1 0]  1343.116178  12.064732   1367.148732\n",
       "3   [0 0 0 1 0 0 0]  1343.747162  11.553305      0.000000\n",
       "0   [1 0 0 0 0 0 0]          NaN        NaN      0.000000\n",
       "1   [0 1 0 0 0 0 0]          NaN        NaN      0.000000\n",
       "2   [0 0 1 0 0 0 0]          NaN        NaN      0.000000\n",
       "4   [0 0 0 0 1 0 0]          NaN        NaN      0.000000\n",
       "6   [0 0 0 0 0 0 1]          NaN        NaN      0.000000\n",
       "7   [1 0 0 1 0 0 0]          NaN        NaN   1366.853772\n",
       "8   [0 1 0 1 0 0 0]          NaN        NaN   1366.853772\n",
       "9   [0 0 1 1 0 0 0]          NaN        NaN   1366.853772\n",
       "10  [0 0 0 1 1 0 0]          NaN        NaN   1366.853772\n",
       "12  [0 0 0 1 0 0 1]          NaN        NaN   1366.853772\n",
       "13  [1 0 0 0 0 1 0]          NaN        NaN   1367.148732\n",
       "14  [0 1 0 0 0 1 0]          NaN        NaN   1367.148732\n",
       "15  [0 0 1 0 0 1 0]          NaN        NaN   1367.148732\n",
       "17  [0 0 0 0 1 1 0]          NaN        NaN   1367.148732\n",
       "18  [0 0 0 0 0 1 1]          NaN        NaN   1367.148732\n",
       "19  [1 0 0 1 0 1 0]          NaN        NaN   1367.245642\n",
       "20  [0 1 0 1 0 1 0]          NaN        NaN   1367.245642\n",
       "21  [0 0 1 1 0 1 0]          NaN        NaN   1367.245642\n",
       "22  [0 0 0 1 1 1 0]          NaN        NaN   1367.245642\n",
       "23  [0 0 0 1 0 1 1]          NaN        NaN   1367.245642"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(\"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point we've only been testing with *3 variables*.  I think it's time to turn it up a notch, and see it handles more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model will be initialized with a number of now expected elements\n",
    "target = 'vote'\n",
    "\n",
    "\n",
    "numeric = np.array(['nage', 'logpopul'])\n",
    "categorical = np.array(['educ', 'income', 'PID', 'selfLR'])\n",
    "# It will probably just internally generate the ranefs for convenience\n",
    "ranefs =  get_ranefs(numeric, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + logpopul | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19300\n",
      "Interrupted at 19,299 [38%]: Average Loss = 1,582.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| income_offset, logpopul| income_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 21400\n",
      "Interrupted at 21,399 [42%]: Average Loss = 1,279.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, PID, Intercept]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 13400\n",
      "Interrupted at 13,399 [26%]: Average Loss = 1,868.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| selfLR_offset, logpopul| selfLR_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19400\n",
      "Interrupted at 19,399 [38%]: Average Loss = 1,437.4\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| income_offset, nage| income_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,011.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], [], ['0 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19800\n",
      "Interrupted at 19,799 [39%]: Average Loss = 1,434\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22600\n",
      "Interrupted at 22,599 [45%]: Average Loss = 1,248.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, Intercept]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['PID'], ['1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23000\n",
      "Interrupted at 22,999 [45%]: Average Loss = 1,334.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, PID, Intercept]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 25100\n",
      "Interrupted at 25,099 [50%]: Average Loss = 1,784\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, PID, educ, Intercept]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24200\n",
      "Interrupted at 24,199 [48%]: Average Loss = 2,026.6\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24900\n",
      "Interrupted at 24,899 [49%]: Average Loss = 2,097.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,304.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, PID, Intercept]\n",
      "There were 35 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.635539885527753, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 907 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.31780144076287675, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['1 + nage | income' '1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 22500\n",
      "Interrupted at 22,499 [44%]: Average Loss = 1,359.9\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, Intercept]\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 62 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['income' 'PID'], ['1 + nage | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 24700\n",
      "Interrupted at 24,699 [49%]: Average Loss = 1,747.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, PID, income, Intercept]\n",
      "There were 80 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6793447308206073, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 182 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6507623216419204, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + logpopul | income' '1 + logpopul | PID' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 26200\n",
      "Interrupted at 26,199 [52%]: Average Loss = 2,044.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, PID, educ, Intercept]\n",
      "There were 56 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7157034995752866, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 105 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['income'], []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19000\n",
      "Interrupted at 18,999 [37%]: Average Loss = 1,918.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, income, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | PID' '1 + logpopul | income' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23900\n",
      "Interrupted at 23,899 [47%]: Average Loss = 2,303.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, PID, educ, Intercept]\n",
      "There were 25 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 67 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "Fitting with the following features: [], ['PID'], ['0 + nage | PID' '1 + nage | income' '1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22700\n",
      "Interrupted at 22,699 [45%]: Average Loss = 1,440.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, 1| income_offset, 1| income_sd, nage| PID_offset, nage| PID_sd, PID, Intercept]\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 24 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      "Fitting with the following features: [], ['educ' 'PID'], ['1 + nage | educ' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 26300\n",
      "Interrupted at 26,299 [52%]: Average Loss = 1,913.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| educ_offset, nage| educ_sd, 1| educ_offset, 1| educ_sd, PID, educ, Intercept]\n",
      "There were 123 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 206 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Fitting with the following features: [], ['PID'], ['0 + nage | selfLR' '1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n",
      "Convergence achieved at 21800\n",
      "Interrupted at 21,799 [43%]: Average Loss = 1,371\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| PID_offset, logpopul| PID_sd, 1| PID_offset, 1| PID_sd, nage| selfLR_offset, nage| selfLR_sd, PID, Intercept]\n",
      "There were 886 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.02504323089484991, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 911 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.3737059451330113, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "INFO (theano.gof.compilelock): Refreshing lock C:\\Users\\Alexander\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.17134-SP0-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-3.6.5-64\\lock_dir\\lock\n"
     ]
    }
   ],
   "source": [
    "models = weighted_sampling_strategy(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0 1 0 0 0 0 0]</td>\n",
       "      <td>1347.364258</td>\n",
       "      <td>12.588133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0 0 1 0 0 0 0]</td>\n",
       "      <td>1344.256783</td>\n",
       "      <td>16.392886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0 1 0 0 1 0 0]</td>\n",
       "      <td>1347.380481</td>\n",
       "      <td>12.785435</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models       scores      error  parent_score    Normed\n",
       "0   [1 0 0 0 0 0 0]          NaN        NaN      0.000000  0.000000\n",
       "1   [0 1 0 0 0 0 0]  1347.364258  12.588133      0.000000  0.000000\n",
       "2   [0 0 1 0 0 0 0]  1344.256783  16.392886      0.000000  0.000000\n",
       "3   [0 0 0 1 0 0 0]          NaN        NaN      0.000000  0.000000\n",
       "4   [0 0 0 0 1 0 0]          NaN        NaN      0.000000  0.000000\n",
       "5   [0 0 0 0 0 1 0]          NaN        NaN      0.000000  0.000000\n",
       "6   [0 0 0 0 0 0 1]          NaN        NaN      0.000000  0.000000\n",
       "7   [1 1 0 0 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "8   [0 1 1 0 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "9   [0 1 0 1 0 0 0]          NaN        NaN   1372.540524  0.801798\n",
       "10  [0 1 0 0 1 0 0]  1347.380481  12.785435   1372.540524  0.801798\n",
       "11  [0 1 0 0 0 1 0]          NaN        NaN   1372.540524  0.801798\n",
       "12  [0 1 0 0 0 0 1]          NaN        NaN   1372.540524  0.801798\n",
       "13  [1 0 1 0 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "14  [0 1 1 0 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "15  [0 0 1 1 0 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "16  [0 0 1 0 1 0 0]          NaN        NaN   1377.042555 -1.309417\n",
       "17  [0 0 1 0 0 1 0]          NaN        NaN   1377.042555 -1.309417\n",
       "18  [0 0 1 0 0 0 1]          NaN        NaN   1377.042555 -1.309417\n",
       "19  [1 1 0 0 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "20  [0 1 1 0 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "21  [0 1 0 1 1 0 0]          NaN        NaN   1372.951351  0.609143\n",
       "22  [0 1 0 0 1 1 0]          NaN        NaN   1372.951351  0.609143\n",
       "23  [0 1 0 0 1 0 1]          NaN        NaN   1372.951351  0.609143"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = calculate_weights(models.sort_values('scores'))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0, 0]]),\n",
       " array([-0.57283494,  1.1546888 , -0.58185386]))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = models[~np.isnan(models.scores)]\n",
    "test_data = models[np.isnan(models.scores)]\n",
    "\n",
    "X_train = np.vstack(train_data.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "X_test = np.vstack(test_data.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "\n",
    "mean = train_data['scores'].mean()\n",
    "std = train_data['scores'].std()\n",
    "\n",
    "train_data['Normed'] = [0 if score == 0 else (-(score-mean)/std) for score in train_data.scores]\n",
    "y_train = train_data.Normed.values\n",
    "\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.261199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.210763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.522399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.682726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>0.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.421527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models  scores  error  parent_score    Normed  predictions\n",
       "0   [1 0 0 0 0 0 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "3   [0 0 0 1 0 0 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "4   [0 0 0 0 1 0 0]     NaN    NaN      0.000000  0.000000     0.050436\n",
       "5   [0 0 0 0 0 1 0]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "6   [0 0 0 0 0 0 1]     NaN    NaN      0.000000  0.000000     0.210763\n",
       "7   [1 1 0 0 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "8   [0 1 1 0 0 0 0]     NaN    NaN   1372.540524  0.801798     0.210763\n",
       "9   [0 1 0 1 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "11  [0 1 0 0 0 1 0]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "12  [0 1 0 0 0 0 1]     NaN    NaN   1372.540524  0.801798    -0.261199\n",
       "13  [1 0 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "14  [0 1 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.210763\n",
       "15  [0 0 1 1 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "16  [0 0 1 0 1 0 0]     NaN    NaN   1377.042555 -1.309417     0.522399\n",
       "17  [0 0 1 0 0 1 0]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "18  [0 0 1 0 0 0 1]     NaN    NaN   1377.042555 -1.309417     0.682726\n",
       "19  [1 1 0 0 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "20  [0 1 1 0 1 0 0]     NaN    NaN   1372.951351  0.609143     0.050436\n",
       "21  [0 1 0 1 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "22  [0 1 0 0 1 1 0]     NaN    NaN   1372.951351  0.609143    -0.421527\n",
       "23  [0 1 0 0 1 0 1]     NaN    NaN   1372.951351  0.609143    -0.421527"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "test_data['predictions'] = clf.predict(X_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>Normed</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0 1 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0 1 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0 1 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.540524</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>-0.472835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1 0 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0 0 1 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.045670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0 0 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0 0 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1377.042555</td>\n",
       "      <td>-1.309417</td>\n",
       "      <td>1.054689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1 1 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>0.281908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0 1 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0 1 0 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0 1 0 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1372.951351</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>-0.481854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             models  scores  error  parent_score    Normed  predictions\n",
       "0   [1 0 0 0 0 0 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "3   [0 0 0 1 0 0 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "4   [0 0 0 0 1 0 0]     NaN    NaN      0.000000  0.000000     0.281908\n",
       "5   [0 0 0 0 0 1 0]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "6   [0 0 0 0 0 0 1]     NaN    NaN      0.000000  0.000000     0.290927\n",
       "7   [1 1 0 0 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "8   [0 1 1 0 0 0 0]     NaN    NaN   1372.540524  0.801798     0.290927\n",
       "9   [0 1 0 1 0 0 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "11  [0 1 0 0 0 1 0]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "12  [0 1 0 0 0 0 1]     NaN    NaN   1372.540524  0.801798    -0.472835\n",
       "13  [1 0 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "14  [0 1 1 0 0 0 0]     NaN    NaN   1377.042555 -1.309417     0.290927\n",
       "15  [0 0 1 1 0 0 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "16  [0 0 1 0 1 0 0]     NaN    NaN   1377.042555 -1.309417     1.045670\n",
       "17  [0 0 1 0 0 1 0]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "18  [0 0 1 0 0 0 1]     NaN    NaN   1377.042555 -1.309417     1.054689\n",
       "19  [1 1 0 0 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "20  [0 1 1 0 1 0 0]     NaN    NaN   1372.951351  0.609143     0.281908\n",
       "21  [0 1 0 1 1 0 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "22  [0 1 0 0 1 1 0]     NaN    NaN   1372.951351  0.609143    -0.481854\n",
       "23  [0 1 0 0 1 0 1]     NaN    NaN   1372.951351  0.609143    -0.481854"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVR(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "test_data['predictions'] = svm.predict(X_test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 5)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.loc[np.isnan(models.scores)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.loc[np.isnan(models.scores)]['Normed'] = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29092693,  0.29092693,  0.281908  ,  0.29092693,  0.29092693,\n",
       "       -0.47283494,  0.29092693, -0.47283494, -0.47283494, -0.47283494,\n",
       "        1.0546888 ,  0.29092693,  1.0546888 ,  1.04566987,  1.0546888 ,\n",
       "        1.0546888 , -0.48185386,  0.281908  , -0.48185386, -0.48185386,\n",
       "       -0.48185386])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weights(all_models, svm, root_offset=1):\n",
    "    \"\"\"Calculates valid probabilites which sum to one\n",
    "    \n",
    "    In our strategy, we want to take into account both the expected\n",
    "    WAIC and the error in the term.  As a result, we'll calculate \n",
    "    actually calculate the upper 95% value, or the mean plus two\n",
    "    standard deviations.  This will help penalize high variance\n",
    "    models. \n",
    "    \"\"\"\n",
    "    # Extracts non-zero parent scores\n",
    "    models = all_models[np.isnan(all_models.scores)]\n",
    "    arr = np.vstack(models.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "    # Calculates mean and std deviation unbiased by zero values\n",
    "    models['pred'] = svm.predict(arr)\n",
    "    # Root offset helps incentive the model to give the root \n",
    "    # variables an opportunity to be run by themselves\n",
    "    models['pred'] = np.where(models.parent_score == 0, models.pred + root_offset, models.pred)\n",
    "    models['p'] = softmax(models.pred)\n",
    "    return models\n",
    "\n",
    "def train_model(all_models):\n",
    "    # Get all nodes which have been evaluated\n",
    "    train_data = all_models[~np.isnan(all_models.scores)]\n",
    "    # Get an input matrix from the model column\n",
    "    X_train = np.vstack(train_data.models.map(lambda x: np.fromstring(x[1:-1], dtype=int, sep=' ')).tolist())\n",
    "    # Precalculate normalization values\n",
    "    mean = train_data['scores'].mean()\n",
    "    std = train_data['scores'].std()\n",
    "    # Norm values\n",
    "    train_data['Normed'] = [0 if score == 0 else (-(score-mean)/std) for score in train_data.scores]\n",
    "    y_train = train_data.Normed.values\n",
    "    # Create instance of support vector machine with linear kernal\n",
    "    svm = SVR(kernel='linear')\n",
    "    # train it\n",
    "    svm.fit(X_train, y_train)    \n",
    "    return svm\n",
    "\n",
    "def predictive_sampling_strategy(samples):\n",
    "    \"\"\"The Predictive Sampling Strategy\n",
    "    \n",
    "    In this model we enhance our weight mechanism with predictions from\n",
    "    a support vector machine for our weights instead the heuristic that's\n",
    "    based on their parent score. \n",
    "    \n",
    "    This will hopefully help us identify related nodes in the tree and \n",
    "    prioritize them automatically. What's kind of cool too is that we don't really \n",
    "    need to change our method too much. \n",
    "    \"\"\"\n",
    "   # We start with no possible moves\n",
    "    models = pd.DataFrame({\"models\": [], \"scores\": [], \"error\": []})\n",
    "    # We would then enumerate the root to give us the first possible models\n",
    "    models = enumerate_node(np.zeros(len(numeric) + len(categorical) + len(ranefs)), models)\n",
    "    # We want to observe the sampling pattern, so we'll also track each iteration\n",
    "    # in a trace.\n",
    "    trace = pd.DataFrame({\"iter\": [], \"model\": [], \"score\": [], \"error\": []})\n",
    "    for i in range(samples):\n",
    "        try:\n",
    "            if (i > 0) & (i % 3 == 0):\n",
    "                svm = train_model(models)\n",
    "            # While we have yet had enough iterations to have \n",
    "            # trained a model, use our weighted strategy from\n",
    "            # before\n",
    "            if i < 3:\n",
    "                weights = calculate_weights(models, root_offset=1)\n",
    "            else:\n",
    "                weights = predict_weights(models, svm, root_offset=1)\n",
    "            # Draw Sample\n",
    "            sample_record = models[np.isnan(models.scores)].sample(1, weights=weights['p'])\n",
    "            sample_string = sample_record['models'].iloc[0]\n",
    "            model_array = np.fromstring(sample_string[1:-1], dtype=int, sep=' ')\n",
    "            #print(model_array)\n",
    "            # We then build and evaluate the WAIC of the model\n",
    "            model = build_model(model_array, (numeric, categorical, ranefs), target, data)\n",
    "            score = evaluate_model(model)\n",
    "            # Update the latest score in the models data\n",
    "            models.loc[models.models == sample_string, \"scores\"] = score[0]\n",
    "            models.loc[models.models == sample_string, \"error\"] = score[1]\n",
    "            # Since we've evaluated that node, we'll also enumerate the child models\n",
    "            # of that node and add them to the list of potential models\n",
    "            models = enumerate_node(model_array, models, parent_score=score[0] + 2*score[1])\n",
    "            # Add values to trace\n",
    "            trace = trace.append({\"iter\": i, \"model\": sample_string, \"score\": score[0], \"error\": score[1]}, ignore_index=True)\n",
    "        except KeyboardInterrupt:\n",
    "            raise    \n",
    "    return models, svm, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19300\n",
      "Interrupted at 19,299 [38%]: Average Loss = 1,588.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| educ_offset, logpopul| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + nage | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 20000\n",
      "Interrupted at 19,999 [39%]: Average Loss = 1,465.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| educ_offset, nage| educ_sd, 1| educ_offset, 1| educ_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + logpopul | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19100\n",
      "Interrupted at 19,099 [38%]: Average Loss = 1,546.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| educ_offset, logpopul| educ_sd, 1| educ_offset, 1| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 21000\n",
      "Interrupted at 20,999 [41%]: Average Loss = 1,269.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + nage | income' '1 + logpopul | educ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 20500\n",
      "Interrupted at 20,499 [40%]: Average Loss = 1,634.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| educ_offset, logpopul| educ_sd, 1| educ_offset, 1| educ_sd, nage| income_offset, nage| income_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | educ' '0 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22300\n",
      "Interrupted at 22,299 [44%]: Average Loss = 1,426\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| PID_offset, logpopul| PID_sd, logpopul| educ_offset, logpopul| educ_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23400\n",
      "Interrupted at 23,399 [46%]: Average Loss = 1,105.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + nage | PID' '1 + nage | selfLR' '1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22800\n",
      "Interrupted at 22,799 [45%]: Average Loss = 1,244.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| PID_offset, logpopul| PID_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 19200\n",
      "Interrupted at 19,199 [38%]: Average Loss = 1,445\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| PID_offset, logpopul| PID_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['1 + nage | PID' '1 + nage | selfLR' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23400\n",
      "Interrupted at 23,399 [46%]: Average Loss = 1,217.4\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| selfLR_offset, logpopul| selfLR_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | educ' '1 + nage | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24400\n",
      "Interrupted at 24,399 [48%]: Average Loss = 1,037.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| educ_offset, logpopul| educ_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['selfLR'], ['1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 28000\n",
      "Interrupted at 27,999 [55%]: Average Loss = 1,702.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, selfLR, Intercept]\n",
      "There were 99 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5375656346905932, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 216 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6110488311316471, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['selfLR'], ['0 + nage | educ' '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 25900\n",
      "Interrupted at 25,899 [51%]: Average Loss = 1,839.4\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, Intercept]\n",
      "There were 506 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.43957414405843964, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 1094 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.31167177928132145, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22900\n",
      "Interrupted at 22,899 [45%]: Average Loss = 1,851.9\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, income, Intercept]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['selfLR'], ['0 + nage | income' '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 28200\n",
      "Interrupted at 28,199 [56%]: Average Loss = 1,751.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, selfLR, Intercept]\n",
      "There were 190 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7042851636468548, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 388 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6506256942017085, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['0 + nage | income' '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 22700\n",
      "Interrupted at 22,699 [45%]: Average Loss = 1,933\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| income_offset, nage| income_sd, income, Intercept]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + nage | selfLR' '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24500\n",
      "Interrupted at 24,499 [48%]: Average Loss = 1,075.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| selfLR_offset, nage| selfLR_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['0 + nage | income' '1 + nage | income' '1 + nage | PID'\n",
      " '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24100\n",
      "Interrupted at 24,099 [48%]: Average Loss = 1,952.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, 1| income_offset, 1| income_sd, nage| income_offset, nage| income_sd, income, Intercept]\n",
      "There were 168 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6440175854286896, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 265 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6571618700268025, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['0 + nage | income' '0 + nage | selfLR' '1 + nage | income'\n",
      " '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24300\n",
      "Interrupted at 24,299 [48%]: Average Loss = 1,973.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, 1| income_offset, 1| income_sd, nage| selfLR_offset, nage| selfLR_sd, nage| income_offset, nage| income_sd, income, Intercept]\n",
      "There were 215 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 1213 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.39500704389300423, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['1 + nage | PID' '1 + nage | selfLR' '1 + logpopul | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23200\n",
      "Interrupted at 23,199 [46%]: Average Loss = 2,152.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, income, Intercept]\n",
      "There were 163 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 234 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['selfLR'], ['0 + nage | educ' '1 + nage | PID' '1 + nage | selfLR'\n",
      " '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24900\n",
      "Interrupted at 24,899 [49%]: Average Loss = 1,932.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| selfLR_offset, logpopul| selfLR_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, Intercept]\n",
      "There were 968 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.07228703938352683, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 1093 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.3326869908070092, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], ['income'], ['0 + nage | income' '0 + logpopul | PID' '1 + nage | income'\n",
      " '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24200\n",
      "Interrupted at 24,199 [48%]: Average Loss = 2,070.8\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, 1| income_offset, 1| income_sd, logpopul| PID_offset, logpopul| PID_sd, nage| income_offset, nage| income_sd, income, Intercept]\n",
      "There were 68 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 870 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.4024205093916569, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['selfLR'], ['0 + nage | educ' '1 + nage | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 29500\n",
      "Interrupted at 29,499 [58%]: Average Loss = 2,047.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, nage, Intercept]\n",
      "There were 91 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6949984636056932, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 292 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6851644825498091, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['selfLR'], ['0 + nage | educ' '1 + nage | PID' '1 + nage | selfLR'\n",
      " '1 + logpopul | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 30000\n",
      "Interrupted at 29,999 [59%]: Average Loss = 2,298.5\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, nage, Intercept]\n",
      "There were 262 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.41211827866744527, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 435 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5510695087682173, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | selfLR' '1 + nage | PID' '1 + nage | selfLR'\n",
      " '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 23900\n",
      "Interrupted at 23,899 [47%]: Average Loss = 1,239\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| selfLR_offset, logpopul| selfLR_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + nage | selfLR' '1 + nage | PID' '1 + nage | selfLR'\n",
      " '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24200\n",
      "Interrupted at 24,199 [48%]: Average Loss = 1,221.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| selfLR_offset, logpopul| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, nage| selfLR_offset, nage| selfLR_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | income' '0 + logpopul | PID' '1 + nage | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 21300\n",
      "Interrupted at 21,299 [42%]: Average Loss = 1,501.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, logpopul| PID_offset, logpopul| PID_sd, logpopul| income_offset, logpopul| income_sd]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['selfLR'], ['0 + nage | educ' '0 + logpopul | PID' '1 + nage | PID'\n",
      " '1 + nage | selfLR' '1 + logpopul | income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 28500\n",
      "Interrupted at 28,499 [56%]: Average Loss = 2,438.3\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| PID_offset, logpopul| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, nage, Intercept]\n",
      "There were 161 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7144210137957276, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 1161 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.3786571853463083, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: [], [], ['0 + logpopul | selfLR' '1 + nage | PID' '1 + nage | selfLR'\n",
      " '1 + logpopul | PID' '1 + logpopul | selfLR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 24600\n",
      "Interrupted at 24,599 [49%]: Average Loss = 1,322.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, Intercept, logpopul| PID_offset, logpopul| PID_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| selfLR_offset, logpopul| selfLR_sd]\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with the following features: ['nage'], ['selfLR'], ['0 + nage | educ' '0 + logpopul | PID' '1 + nage | PID'\n",
      " '1 + nage | selfLR' '1 + logpopul | income' '1 + logpopul | PID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Convergence achieved at 30000\n",
      "Interrupted at 29,999 [59%]: Average Loss = 2,431.2\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [vote_sd, logpopul| income_offset, logpopul| income_sd, 1| income_offset, 1| income_sd, nage| selfLR_offset, nage| selfLR_sd, 1| selfLR_offset, 1| selfLR_sd, nage| PID_offset, nage| PID_sd, 1| PID_offset, 1| PID_sd, logpopul| PID_offset, logpopul| PID_sd, nage| educ_offset, nage| educ_sd, selfLR, nage, Intercept]\n",
      "There were 871 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.01635184013012039, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 928 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.4254920771941988, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models, svm, trace = predictive_sampling_strategy(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x222f9e32b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace.score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>1321.227344</td>\n",
       "      <td>14.385184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>1343.504695</td>\n",
       "      <td>12.027565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>1322.004579</td>\n",
       "      <td>14.601432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]</td>\n",
       "      <td>920.632495</td>\n",
       "      <td>41.675683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>1322.644436</td>\n",
       "      <td>14.746603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>1113.154033</td>\n",
       "      <td>27.550883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>280.872928</td>\n",
       "      <td>78.817142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]</td>\n",
       "      <td>278.098293</td>\n",
       "      <td>79.103181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]</td>\n",
       "      <td>817.500664</td>\n",
       "      <td>42.984697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]</td>\n",
       "      <td>281.732932</td>\n",
       "      <td>78.764144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]</td>\n",
       "      <td>303.672340</td>\n",
       "      <td>80.584469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>282.886054</td>\n",
       "      <td>78.269227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>282.037068</td>\n",
       "      <td>78.850266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>304.728222</td>\n",
       "      <td>76.951904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>[0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>283.970663</td>\n",
       "      <td>78.010372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>308.339595</td>\n",
       "      <td>76.999747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>282.220842</td>\n",
       "      <td>78.730120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0]</td>\n",
       "      <td>307.059800</td>\n",
       "      <td>76.723540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0]</td>\n",
       "      <td>301.698402</td>\n",
       "      <td>77.932109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>306.154712</td>\n",
       "      <td>76.869075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]</td>\n",
       "      <td>280.131712</td>\n",
       "      <td>78.626232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0]</td>\n",
       "      <td>299.970567</td>\n",
       "      <td>76.490117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>286.837397</td>\n",
       "      <td>78.403812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>290.035091</td>\n",
       "      <td>77.865311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1]</td>\n",
       "      <td>281.202796</td>\n",
       "      <td>78.663733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1]</td>\n",
       "      <td>282.078762</td>\n",
       "      <td>78.661809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]</td>\n",
       "      <td>819.398219</td>\n",
       "      <td>42.954353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>281.058572</td>\n",
       "      <td>80.273352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1]</td>\n",
       "      <td>279.577448</td>\n",
       "      <td>78.843832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>282.632066</td>\n",
       "      <td>76.533540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iter                                          model        score  \\\n",
       "0    0.0  [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]  1321.227344   \n",
       "1    1.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]  1343.504695   \n",
       "2    2.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]  1322.004579   \n",
       "3    3.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]   920.632495   \n",
       "4    4.0  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]  1322.644436   \n",
       "5    5.0  [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]  1113.154033   \n",
       "6    6.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   280.872928   \n",
       "7    7.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0]   278.098293   \n",
       "8    8.0  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]   817.500664   \n",
       "9    9.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]   281.732932   \n",
       "10  10.0  [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]   303.672340   \n",
       "11  11.0  [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   282.886054   \n",
       "12  12.0  [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   282.037068   \n",
       "13  13.0  [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   304.728222   \n",
       "14  14.0  [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   283.970663   \n",
       "15  15.0  [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   308.339595   \n",
       "16  16.0  [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0]   282.220842   \n",
       "17  17.0  [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0]   307.059800   \n",
       "18  18.0  [0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0]   301.698402   \n",
       "19  19.0  [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]   306.154712   \n",
       "20  20.0  [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1]   280.131712   \n",
       "21  21.0  [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0]   299.970567   \n",
       "22  22.0  [1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]   286.837397   \n",
       "23  23.0  [1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0]   290.035091   \n",
       "24  24.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1]   281.202796   \n",
       "25  25.0  [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1]   282.078762   \n",
       "26  26.0  [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]   819.398219   \n",
       "27  27.0  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]   281.058572   \n",
       "28  28.0  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1]   279.577448   \n",
       "29  29.0  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]   282.632066   \n",
       "\n",
       "        error  \n",
       "0   14.385184  \n",
       "1   12.027565  \n",
       "2   14.601432  \n",
       "3   41.675683  \n",
       "4   14.746603  \n",
       "5   27.550883  \n",
       "6   78.817142  \n",
       "7   79.103181  \n",
       "8   42.984697  \n",
       "9   78.764144  \n",
       "10  80.584469  \n",
       "11  78.269227  \n",
       "12  78.850266  \n",
       "13  76.951904  \n",
       "14  78.010372  \n",
       "15  76.999747  \n",
       "16  78.730120  \n",
       "17  76.723540  \n",
       "18  77.932109  \n",
       "19  76.869075  \n",
       "20  78.626232  \n",
       "21  76.490117  \n",
       "22  78.403812  \n",
       "23  77.865311  \n",
       "24  78.663733  \n",
       "25  78.661809  \n",
       "26  42.954353  \n",
       "27  80.273352  \n",
       "28  78.843832  \n",
       "29  76.533540  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "      <th>error</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>pred</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-2.166257</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-2.165473</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.885414</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1349.997713</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.884631</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.883764</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.883764</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.883764</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1367.559825</td>\n",
       "      <td>-1.876984</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>[0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.137643</td>\n",
       "      <td>-1.832929</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>[1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>[1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>[1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.645021</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439.737599</td>\n",
       "      <td>0.678774</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.605276</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>[0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.384176</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>[0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452.950801</td>\n",
       "      <td>0.683904</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.304655</td>\n",
       "      <td>0.684688</td>\n",
       "      <td>0.003123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.265112</td>\n",
       "      <td>0.685554</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>[1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.685637</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>[1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>[1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.686421</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>[1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>435.699146</td>\n",
       "      <td>0.687287</td>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916238</td>\n",
       "      <td>0.003936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            models  scores  error  \\\n",
       "113  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "59   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "50   [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "46   [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "60   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]     NaN    NaN   \n",
       "56   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]     NaN    NaN   \n",
       "55   [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "53   [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "35   [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "52   [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "51   [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "47   [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "43   [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "44   [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "45   [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "49   [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "48   [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]     NaN    NaN   \n",
       "62   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]     NaN    NaN   \n",
       "61   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]     NaN    NaN   \n",
       "102  [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "103  [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "117  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0]     NaN    NaN   \n",
       "114  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0]     NaN    NaN   \n",
       "112  [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "110  [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "109  [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "108  [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "107  [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "100  [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "101  [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]     NaN    NaN   \n",
       "..                                             ...     ...    ...   \n",
       "501  [1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "512  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0]     NaN    NaN   \n",
       "510  [1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "509  [1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "508  [1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "507  [1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "506  [1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "504  [1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "503  [1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "502  [1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0]     NaN    NaN   \n",
       "424  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]     NaN    NaN   \n",
       "260  [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0]     NaN    NaN   \n",
       "515  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1]     NaN    NaN   \n",
       "393  [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]     NaN    NaN   \n",
       "413  [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0]     NaN    NaN   \n",
       "172  [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0]     NaN    NaN   \n",
       "528  [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1]     NaN    NaN   \n",
       "537  [1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "533  [1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "534  [1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "535  [1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "536  [1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "538  [1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "539  [1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "540  [1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "541  [1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "542  [1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0]     NaN    NaN   \n",
       "544  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0]     NaN    NaN   \n",
       "546  [1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1]     NaN    NaN   \n",
       "16   [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]     NaN    NaN   \n",
       "\n",
       "     parent_score      pred         p  \n",
       "113   1352.137643 -2.166257  0.000180  \n",
       "59    1367.559825 -2.165473  0.000181  \n",
       "50    1367.559825 -1.885414  0.000239  \n",
       "46    1367.559825 -1.884631  0.000239  \n",
       "60    1367.559825 -1.884631  0.000239  \n",
       "56    1367.559825 -1.884631  0.000239  \n",
       "55    1367.559825 -1.884631  0.000239  \n",
       "53    1367.559825 -1.884631  0.000239  \n",
       "35    1349.997713 -1.884631  0.000239  \n",
       "52    1367.559825 -1.884631  0.000239  \n",
       "51    1367.559825 -1.884631  0.000239  \n",
       "47    1367.559825 -1.884631  0.000239  \n",
       "43    1367.559825 -1.884631  0.000239  \n",
       "44    1367.559825 -1.884631  0.000239  \n",
       "45    1367.559825 -1.884631  0.000239  \n",
       "49    1367.559825 -1.883764  0.000239  \n",
       "48    1367.559825 -1.883764  0.000239  \n",
       "62    1367.559825 -1.883764  0.000239  \n",
       "61    1367.559825 -1.876984  0.000241  \n",
       "102   1352.137643 -1.832929  0.000252  \n",
       "103   1352.137643 -1.832929  0.000252  \n",
       "117   1352.137643 -1.832929  0.000252  \n",
       "114   1352.137643 -1.832929  0.000252  \n",
       "112   1352.137643 -1.832929  0.000252  \n",
       "110   1352.137643 -1.832929  0.000252  \n",
       "109   1352.137643 -1.832929  0.000252  \n",
       "108   1352.137643 -1.832929  0.000252  \n",
       "107   1352.137643 -1.832929  0.000252  \n",
       "100   1352.137643 -1.832929  0.000252  \n",
       "101   1352.137643 -1.832929  0.000252  \n",
       "..            ...       ...       ...  \n",
       "501    441.605276  0.678774  0.003104  \n",
       "512    441.605276  0.678774  0.003104  \n",
       "510    441.605276  0.678774  0.003104  \n",
       "509    441.605276  0.678774  0.003104  \n",
       "508    441.605276  0.678774  0.003104  \n",
       "507    441.605276  0.678774  0.003104  \n",
       "506    441.605276  0.678774  0.003104  \n",
       "504    441.605276  0.678774  0.003104  \n",
       "503    441.605276  0.678774  0.003104  \n",
       "502    441.605276  0.678774  0.003104  \n",
       "424    443.645021  0.678774  0.003104  \n",
       "260    439.737599  0.678774  0.003104  \n",
       "515    441.605276  0.679641  0.003107  \n",
       "393    437.384176  0.679641  0.003107  \n",
       "413    452.950801  0.683904  0.003120  \n",
       "172    436.304655  0.684688  0.003123  \n",
       "528    437.265112  0.685554  0.003125  \n",
       "537    435.699146  0.685637  0.003125  \n",
       "533    435.699146  0.686421  0.003128  \n",
       "534    435.699146  0.686421  0.003128  \n",
       "535    435.699146  0.686421  0.003128  \n",
       "536    435.699146  0.686421  0.003128  \n",
       "538    435.699146  0.686421  0.003128  \n",
       "539    435.699146  0.686421  0.003128  \n",
       "540    435.699146  0.686421  0.003128  \n",
       "541    435.699146  0.686421  0.003128  \n",
       "542    435.699146  0.686421  0.003128  \n",
       "544    435.699146  0.686421  0.003128  \n",
       "546    435.699146  0.687287  0.003131  \n",
       "16       0.000000  0.916238  0.003936  \n",
       "\n",
       "[517 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_weights(models, svm).sort_values(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mcts(object):\n",
    "    \n",
    "    def __init__(self, numeric, categorical, target):\n",
    "        self.target = target\n",
    "        self.numeric = np.array(numeric)\n",
    "        self.categorical = np.array(categorical)\n",
    "        self.ranefs = self.get_ranefs(numeric, categorical)\n",
    "        self.n_numeric = len(numeric)\n",
    "        self.n_categorical = len(categorical)\n",
    "        self.n_vars = len(numeric) + len(categorical) + len(self.ranefs)\n",
    "        self.root_node = np.zeros(self.n_vars, np.int32)\n",
    "        \n",
    "    \n",
    "    def enumerate_node(self, model_array, models, parent_score=0):\n",
    "        \"\"\"Enumerates all possible models which build off of the given model\"\"\"\n",
    "        model_array = np.array(model_array)\n",
    "        for ix, val in enumerate(model_array):\n",
    "            if val != 1:\n",
    "                move = model_array.copy()\n",
    "                move[ix] = 1\n",
    "                models = models.append({\"models\":str(move.astype('int')), \"parent_score\":parent_score}, ignore_index=True)\n",
    "        return models\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_ranefs(numeric, categorical):\n",
    "        '''Generates a list of ranefs\n",
    "        Given just the list of numeric and categorical variables, we can generate\n",
    "        a list of all potential features we might explore.\n",
    "        '''\n",
    "        random_slopes = [f'0 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "        random_linear = [f'1 + {num} | {cat}' for num in numeric for cat in categorical]\n",
    "        return np.array(random_slopes + random_linear)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = mcts(numeric, categorical, target)\n",
    "search.model_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
